# -*- coding: utf-8 -*-
"""Web-Scrapping and Langchain

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xrsfyp9rVAiCb63JIfEV682isk-37iCL
"""

!pip install requests
!pip install beautifulsoup4
!pip install cohere
!pip install langchain cohere faiss-cpu
!pip install openai
!pip install -U langchain-community
!pip install langchain faiss-cpu cohere tiktoken
!pip install flask flask-ngrok

import requests
from bs4 import BeautifulSoup

web=requests.get("https://www.ekaimpact.org/")
print(web)

web.content

soup=BeautifulSoup(web.content,"html.parser")

print(soup.prettify())

tag=soup.html

type(tag)

tag=soup.a
tag

soup.title

soup.head()

soup.body

soup.find("h1")

soup.find_all("h1")

class_data=soup.find("div",class_="wixDesktopViewport")

for i in soup.find_all("a"):
  print(i.get("href"))

img=soup.find_all("img")

for i in img:
  print(i.get("src"))

text=soup.get_text(separator="/n",strip=True)

with open("eka_site_content.txt", "w", encoding="utf-8") as f:
    f.write(text)

print("âœ… Scraped content saved to eka_site_content.txt")

with open("eka_site_content.txt","r",encoding="utf-8")as f:
  raw_text=f.read()

  lines=[line.strip()for line in raw_text.split("\n")if len(line.strip())>40]
  cleaned_text="\n".join(lines)
  with open("eka_cleaned.txt", "w", encoding="utf-8") as f:
    f.write(cleaned_text)

import cohere

co = cohere.Client("zJNR0dOqvUypmGWWcCZJdyaH5WCa1uyViiF3qHv8")
# Load your cleaned text
with open("eka_cleaned.txt", "r", encoding="utf-8") as f:
    content = f.read()

prompt = f"""Summarize the NGO website content below into the following sections:
- Mission
- Programs
- Goals
- Impact
- Partners
- Contact Info

Website Content:
{content}

Summary:
"""

response = co.generate(
    model='command',
    prompt=prompt,
    max_tokens=400,
    temperature=0.5
)

summary = response.generations[0].text.strip()

# Save to file
with open("eka_cleaned.txt", "w", encoding="utf-8") as f:
    f.write(summary)

from langchain.document_loaders import TextLoader
from langchain.text_splitter import CharacterTextSplitter
loader=TextLoader("eka_site_content.txt")
documents=loader.load()

text_splitter=CharacterTextSplitter(
    separator="\n",
    chunk_size=300,
    chunk_overlap=50,
)

docs=text_splitter.split_documents(documents)

import cohere
from langchain.embeddings.base import Embeddings

class MyCohereEmbedder(Embeddings):
    def __init__(self, api_key: str):
        self.client = cohere.Client(api_key)

    def embed_documents(self, texts):
        response = self.client.embed(
            texts=texts,
            model="embed-english-v3.0",
            input_type="search_document"
        )
        return response.embeddings

    def embed_query(self, text):
        response = self.client.embed(
            texts=[text],
            model="embed-english-v3.0",
            input_type="search_query"
        )
        return response.embeddings[0]

embedding = MyCohereEmbedder(api_key="zJNR0dOqvUypmGWWcCZJdyaH5WCa1uyViiF3qHv8")

from langchain.vectorstores import FAISS
vectorstore = FAISS.from_documents(docs, embedding)

from langchain.llms.base import LLM
from pydantic import Field
from typing import Optional, List
import cohere

class CohereLLM(LLM):
    api_key: str
    model: str = "command"
    temperature: float = 0.5
    max_tokens: int = 1000
    cohere_client: Optional[cohere.Client] = Field(default=None, exclude=True)

    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.cohere_client = cohere.Client(self.api_key)

    @property
    def _llm_type(self) -> str:
        return "cohere-custom"

    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:
        response = self.cohere_client.generate(
            model=self.model,
            prompt=prompt,
            max_tokens=self.max_tokens,
            temperature=self.temperature,
            stop_sequences=stop or []
        )
        return response.generations[0].text.strip()

from langchain.chains import RetrievalQA
from langchain.chat_models import ChatOpenAI

llm = CohereLLM(api_key="zJNR0dOqvUypmGWWcCZJdyaH5WCa1uyViiF3qHv8")

from langchain.chains import RetrievalQA

qa = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=vectorstore.as_retriever(),

)


result = qa.run("What kind of social work does EkaImpact do?")
print(result)

result = qa.run("Where is EkaImpact based?")
print(result)

result = qa.run("Who founded EkaImpact?")
print(result)

result = qa.run("What are the main programs run by EkaImpact?")
print(result)

result = qa.run("What does EkaImpact do in the healthcare sector?")
print(result)

result = qa.run("what is Neev Ki Eent Foundation")
print(result)

result = qa.run("What is EkaImpact Vison?")
print(result)

result = qa.run("What is EkaImpact mission?")
print(result)

result=qa.run("How can we join Ekaimpact?")
print(result)

result=qa.run("how can we get in touch with Ekaimpact?")
print(result)